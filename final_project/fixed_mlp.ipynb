{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics \n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install sklearn\n",
    "#!pip install keras\n",
    "#!pip install d2l\n",
    "#!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If pandas is not installed, please uncomment the following line:\n",
    "#!pip install pandas\n",
    "#!pip install sklearn\n",
    "%matplotlib inline\n",
    "import d2l\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST-LASSO STARTS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = pd.read_csv('filtered.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered['HADM_ID'] = filtered.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert = pd.read_pickle('bert.pkl')\n",
    "bert = pd.read_pickle('bert_5491.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df = pd.merge(filtered, bert, on='HADM_ID',\n",
    "              how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df['VEC'] = bert_df['VEC'].apply(lambda d: d if isinstance(d, np.ndarray) else [[0]]*768)\n",
    "bert_df = pd.merge(bert_df.iloc[:,:-1], \n",
    "                   pd.DataFrame(bert_df.VEC.values.tolist(), index= bert_df.HADM_ID).applymap(lambda x: x[0]),\n",
    "                   on='HADM_ID',\n",
    "                   how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras mlp : without bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered = pd.read_csv('filtered.csv')\n",
    "X = filtered.drop(columns = ['Unnamed: 0', 'LOS'])\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = filtered['LOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_demo, X_test_demo, y_train_demo, y_test_demo = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = X_train_demo\n",
    "y_train = y_train_demo\n",
    "X_test = X_test_demo\n",
    "y_test = y_test_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "training data dims: X: (47102, 121), y: (47102,)\n",
      "test data dims: X: (11776, 121), y: (11776,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/gluon/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "47102/47102 [==============================] - 2s 52us/step - loss: 136906.3112\n",
      "Epoch 2/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 114986.6317\n",
      "Epoch 3/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 89067.1823\n",
      "Epoch 4/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 67024.9990\n",
      "Epoch 5/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 51845.8183\n",
      "Epoch 6/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 42613.9067\n",
      "Epoch 7/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 35985.2902\n",
      "Epoch 8/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 32246.4301\n",
      "Epoch 9/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 30338.6765\n",
      "Epoch 10/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 28142.7779\n",
      "Epoch 11/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 27141.0500\n",
      "Epoch 12/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 26661.2426\n",
      "Epoch 13/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 25671.3884\n",
      "Epoch 14/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 24860.3888\n",
      "Epoch 15/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 23895.8414\n",
      "Epoch 16/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 23960.1045\n",
      "Epoch 17/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 22543.0335\n",
      "Epoch 18/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 22186.3103\n",
      "Epoch 19/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 21777.5122\n",
      "Epoch 20/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 21663.5363\n",
      "Epoch 21/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 21197.9498\n",
      "Epoch 22/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 20721.7297\n",
      "Epoch 23/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 20599.8752\n",
      "Epoch 24/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 19974.2194\n",
      "Epoch 25/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 19678.2857\n",
      "Epoch 26/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 19188.0797\n",
      "Epoch 27/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 19031.1124\n",
      "Epoch 28/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 18472.4709\n",
      "Epoch 29/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 18905.0525\n",
      "Epoch 30/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 18432.0828\n",
      "Epoch 31/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 17976.8445\n",
      "Epoch 32/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 18094.6216\n",
      "Epoch 33/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 17516.5972\n",
      "Epoch 34/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 17210.8887\n",
      "Epoch 35/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 17425.5215\n",
      "Epoch 36/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 16906.1118\n",
      "Epoch 37/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 16550.9251\n",
      "Epoch 38/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 16630.3236\n",
      "Epoch 39/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 16201.9998\n",
      "Epoch 40/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 16416.0840\n",
      "Epoch 41/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 16645.7180\n",
      "Epoch 42/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 16144.7022\n",
      "Epoch 43/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 15930.5440\n",
      "Epoch 44/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 15609.9686\n",
      "Epoch 45/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 15959.0627\n",
      "Epoch 46/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 15272.7084\n",
      "Epoch 47/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 15304.3650\n",
      "Epoch 48/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 15135.3160\n",
      "Epoch 49/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 14634.2282\n",
      "Epoch 50/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 14776.2981\n",
      "Epoch 51/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 14725.0229\n",
      "Epoch 52/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 14434.9344\n",
      "Epoch 53/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 14587.8086\n",
      "Epoch 54/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 14435.0984\n",
      "Epoch 55/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 14146.3671\n",
      "Epoch 56/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 14122.5561\n",
      "Epoch 57/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 14184.0060\n",
      "Epoch 58/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 13810.3859\n",
      "Epoch 59/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 14132.8719\n",
      "Epoch 60/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 13676.3226\n",
      "Epoch 61/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 13639.7925\n",
      "Epoch 62/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 13798.9051\n",
      "Epoch 63/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 13513.1583\n",
      "Epoch 64/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 13133.9778\n",
      "Epoch 65/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 13216.1646\n",
      "Epoch 66/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 13195.3566\n",
      "Epoch 67/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 13021.8462\n",
      "Epoch 68/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 12858.1073\n",
      "Epoch 69/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 13138.4901\n",
      "Epoch 70/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 12825.1838\n",
      "Epoch 71/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 12696.6850\n",
      "Epoch 72/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 12674.3813\n",
      "Epoch 73/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 12817.8036\n",
      "Epoch 74/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 12561.2738\n",
      "Epoch 75/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 12475.9615\n",
      "Epoch 76/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 12270.3033\n",
      "Epoch 77/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 12552.3036\n",
      "Epoch 78/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 12480.1203\n",
      "Epoch 79/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 12220.0322\n",
      "Epoch 80/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 12296.2660\n",
      "Epoch 81/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 12037.8732\n",
      "Epoch 82/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11912.3581\n",
      "Epoch 83/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11976.6176\n",
      "Epoch 84/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 12165.2257\n",
      "Epoch 85/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11992.9692\n",
      "Epoch 86/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11573.0166\n",
      "Epoch 87/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11604.7387\n",
      "Epoch 88/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 11529.0946\n",
      "Epoch 89/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 11762.2663\n",
      "Epoch 90/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11425.9251\n",
      "Epoch 91/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11881.8620\n",
      "Epoch 92/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 11354.7790\n",
      "Epoch 93/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11304.8725\n",
      "Epoch 94/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11223.6711\n",
      "Epoch 95/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 11051.0418\n",
      "Epoch 96/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 11044.5073\n",
      "Epoch 97/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11227.3090\n",
      "Epoch 98/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10972.7564\n",
      "Epoch 99/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11278.4422\n",
      "Epoch 100/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10980.1060\n",
      "Epoch 101/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10846.7477\n",
      "Epoch 102/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 11011.2959\n",
      "Epoch 103/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10859.1743\n",
      "Epoch 104/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10740.7906\n",
      "Epoch 105/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10531.4864\n",
      "Epoch 106/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 10687.3994\n",
      "Epoch 107/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 10731.4091\n",
      "Epoch 108/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10469.6211\n",
      "Epoch 109/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 10483.2280\n",
      "Epoch 110/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10884.7746\n",
      "Epoch 111/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10366.7285\n",
      "Epoch 112/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10539.3800\n",
      "Epoch 113/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10693.1031\n",
      "Epoch 114/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 10643.9567\n",
      "Epoch 115/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10376.1970\n",
      "Epoch 116/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10116.7735\n",
      "Epoch 117/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10020.2125\n",
      "Epoch 118/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10044.9531\n",
      "Epoch 119/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 10117.3962\n",
      "Epoch 120/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9907.5737\n",
      "Epoch 121/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10031.0904\n",
      "Epoch 122/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10179.6445\n",
      "Epoch 123/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10117.7135\n",
      "Epoch 124/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10221.5851\n",
      "Epoch 125/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10314.9946\n",
      "Epoch 126/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10027.4047\n",
      "Epoch 127/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9896.4958\n",
      "Epoch 128/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9917.8327\n",
      "Epoch 129/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9718.8343\n",
      "Epoch 130/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 10355.6033\n",
      "Epoch 131/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9566.5651\n",
      "Epoch 132/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 9613.1739\n",
      "Epoch 133/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9353.2445\n",
      "Epoch 134/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9646.7478\n",
      "Epoch 135/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9700.0072\n",
      "Epoch 136/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9746.8391\n",
      "Epoch 137/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9538.6596\n",
      "Epoch 138/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9687.2494\n",
      "Epoch 139/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 9510.0279\n",
      "Epoch 140/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9662.1898\n",
      "Epoch 141/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 9440.4672\n",
      "Epoch 142/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9292.5903\n",
      "Epoch 143/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 9272.3488\n",
      "Epoch 144/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9268.7374\n",
      "Epoch 145/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 9297.7922\n",
      "Epoch 146/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 9337.8492\n",
      "Epoch 147/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 9251.9290\n",
      "Epoch 148/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9066.8934\n",
      "Epoch 149/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 9349.0039\n",
      "Epoch 150/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9484.9660\n",
      "Epoch 151/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 9287.0664\n",
      "Epoch 152/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9157.3433\n",
      "Epoch 153/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9134.3579\n",
      "Epoch 154/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 9124.2679\n",
      "Epoch 155/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9224.2580\n",
      "Epoch 156/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9041.1921\n",
      "Epoch 157/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9146.5034\n",
      "Epoch 158/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9131.8089\n",
      "Epoch 159/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9054.1894\n",
      "Epoch 160/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8956.0797\n",
      "Epoch 161/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8759.6173\n",
      "Epoch 162/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8858.7296\n",
      "Epoch 163/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8791.8298\n",
      "Epoch 164/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8613.5263\n",
      "Epoch 165/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8970.4364\n",
      "Epoch 166/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8927.3086\n",
      "Epoch 167/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8819.1984\n",
      "Epoch 168/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8815.8464\n",
      "Epoch 169/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8981.8249\n",
      "Epoch 170/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8742.5921\n",
      "Epoch 171/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8420.7650\n",
      "Epoch 172/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8791.1160\n",
      "Epoch 173/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8744.3967\n",
      "Epoch 174/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 9017.0809\n",
      "Epoch 175/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8745.0516\n",
      "Epoch 176/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8726.0765\n",
      "Epoch 177/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8481.8547\n",
      "Epoch 178/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8603.0224\n",
      "Epoch 179/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8512.2017\n",
      "Epoch 180/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8825.5483\n",
      "Epoch 181/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8560.5560\n",
      "Epoch 182/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8439.5130\n",
      "Epoch 183/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8142.0061\n",
      "Epoch 184/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8467.9314\n",
      "Epoch 185/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8353.8133\n",
      "Epoch 186/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8370.6878\n",
      "Epoch 187/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8207.9743\n",
      "Epoch 188/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8457.4119\n",
      "Epoch 189/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8442.5215\n",
      "Epoch 190/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8441.8291\n",
      "Epoch 191/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8389.2120\n",
      "Epoch 192/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8235.2527\n",
      "Epoch 193/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8334.9674\n",
      "Epoch 194/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8240.9924\n",
      "Epoch 195/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8321.4538\n",
      "Epoch 196/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8380.8548\n",
      "Epoch 197/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 8454.1157\n",
      "Epoch 198/200\n",
      "47102/47102 [==============================] - 1s 24us/step - loss: 7961.4726\n",
      "Epoch 199/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 7925.6172\n",
      "Epoch 200/200\n",
      "47102/47102 [==============================] - 1s 23us/step - loss: 8016.4939\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers, optimizers\n",
    "model = Sequential()\n",
    "model.add(Dense(256, kernel_initializer = 'normal', activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "#model.add(Dense(64, kernel_initializer = 'normal', activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1, \n",
    "                             momentum=0.99, epsilon=0.001, \n",
    "                             center=True, scale=True, \n",
    "                             beta_initializer='zeros', \n",
    "                             gamma_initializer='ones', \n",
    "                             moving_mean_initializer='zeros', \n",
    "                             moving_variance_initializer='ones', \n",
    "                             beta_regularizer=None, gamma_regularizer=None, \n",
    "                             beta_constraint=None, gamma_constraint=None))\n",
    "model.add(Dense(128, activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1, \n",
    "                             momentum=0.99, epsilon=0.001, \n",
    "                             center=True, scale=True, \n",
    "                             beta_initializer='zeros', \n",
    "                             gamma_initializer='ones', \n",
    "                             moving_mean_initializer='zeros', \n",
    "                             moving_variance_initializer='ones', \n",
    "                             beta_regularizer=None, gamma_regularizer=None, \n",
    "                             beta_constraint=None, gamma_constraint=None))\n",
    "model.add(Dense(1))\n",
    "#model.compile(loss = 'rmse', optimizer = 'adam')\n",
    "adm = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f'training data dims: X: {X_train.shape}, y: {y_train.shape}')\n",
    "print(f'test data dims: X: {X_test.shape}, y: {y_test.shape}')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 200, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5306586037849"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.sqrt(8016.4939)\n",
    "b = 19.762\n",
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.16355298913043478\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = predictions.reshape(len(y_test),)\n",
    "difference = predictions - y_test \n",
    "threshold_15 = 0.15*y_test\n",
    "acc_test_15 = sum(threshold_15 - abs(difference) > 0) / len(y_test)\n",
    "print('test accuracy: ', acc_test_15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.3668634028279054\n"
     ]
    }
   ],
   "source": [
    "predictions_train = model.predict(X_train)\n",
    "predictions_train = predictions_train.reshape(len(y_train), )\n",
    "threshold_train = 0.15*y_train\n",
    "difference_train = predictions_train - y_train\n",
    "acc_train = sum(threshold_train - abs(difference_train) > 0) / len(y_train)\n",
    "print('train accuracy: ',acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sqrt(history.history['loss']))\n",
    "plt.title('no bert RMSE history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.savefig('no_bert_rmse.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered = pd.read_csv('filtered.csv')\n",
    "X = bert_df.drop(columns = ['Unnamed: 0'])\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = filtered.iloc[:,121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_demo, X_test_demo, y_train_demo, y_test_demo = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = X_train_demo\n",
    "y_train = y_train_demo\n",
    "X_test = X_test_demo\n",
    "y_test = y_test_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "training data dims: X: (47102, 890), y: (47102,)\n",
      "test data dims: X: (11776, 890), y: (11776,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/gluon/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "47102/47102 [==============================] - 6s 133us/step - loss: 134382.3217\n",
      "Epoch 2/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 101200.4479\n",
      "Epoch 3/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 65139.3885\n",
      "Epoch 4/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 35908.5646\n",
      "Epoch 5/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 17579.1704\n",
      "Epoch 6/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 9433.7458\n",
      "Epoch 7/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 5432.3373\n",
      "Epoch 8/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 4155.0276\n",
      "Epoch 9/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 2937.2617\n",
      "Epoch 10/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 2466.9982\n",
      "Epoch 11/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 2011.7717\n",
      "Epoch 12/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 2229.6522\n",
      "Epoch 13/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 1950.1132\n",
      "Epoch 14/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 1657.1371\n",
      "Epoch 15/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 1511.9233\n",
      "Epoch 16/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 1268.5059\n",
      "Epoch 17/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 1172.3268\n",
      "Epoch 18/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 1093.1467\n",
      "Epoch 19/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 924.8434\n",
      "Epoch 20/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 991.5069\n",
      "Epoch 21/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 1039.1767\n",
      "Epoch 22/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 980.1130\n",
      "Epoch 23/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 1085.0747\n",
      "Epoch 24/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 856.6570\n",
      "Epoch 25/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 896.3014\n",
      "Epoch 26/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 841.1470\n",
      "Epoch 27/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 1080.6380\n",
      "Epoch 28/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 776.2330\n",
      "Epoch 29/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 673.4945\n",
      "Epoch 30/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 637.8162\n",
      "Epoch 31/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 766.3288\n",
      "Epoch 32/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 786.3475\n",
      "Epoch 33/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 845.1219\n",
      "Epoch 34/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 708.1147\n",
      "Epoch 35/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 675.7983\n",
      "Epoch 36/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 690.1138\n",
      "Epoch 37/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 698.1975\n",
      "Epoch 38/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 688.2549\n",
      "Epoch 39/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 798.0294\n",
      "Epoch 40/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 739.4705\n",
      "Epoch 41/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 646.2863\n",
      "Epoch 42/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 615.2408\n",
      "Epoch 43/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 627.9809\n",
      "Epoch 44/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 543.8038\n",
      "Epoch 45/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 643.7448\n",
      "Epoch 46/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 540.9324\n",
      "Epoch 47/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 578.0431\n",
      "Epoch 48/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 636.0581\n",
      "Epoch 49/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 626.9264\n",
      "Epoch 50/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 708.5059\n",
      "Epoch 51/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 649.6779\n",
      "Epoch 52/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 532.4668\n",
      "Epoch 53/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 590.1054\n",
      "Epoch 54/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 664.4080\n",
      "Epoch 55/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 516.1539\n",
      "Epoch 56/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 651.2850\n",
      "Epoch 57/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 640.7097\n",
      "Epoch 58/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 514.2920\n",
      "Epoch 59/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 581.5776\n",
      "Epoch 60/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 516.4131\n",
      "Epoch 61/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 584.4972\n",
      "Epoch 62/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 572.7560\n",
      "Epoch 63/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 558.3109\n",
      "Epoch 64/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 525.2143\n",
      "Epoch 65/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 573.2621\n",
      "Epoch 66/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 469.7915\n",
      "Epoch 67/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 649.3303\n",
      "Epoch 68/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 468.8273\n",
      "Epoch 69/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 506.0079\n",
      "Epoch 70/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 479.2429\n",
      "Epoch 71/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 516.9908\n",
      "Epoch 72/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 507.2045\n",
      "Epoch 73/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 565.3461\n",
      "Epoch 74/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 670.0933\n",
      "Epoch 75/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 554.0027\n",
      "Epoch 76/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 486.5112\n",
      "Epoch 77/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 565.5370\n",
      "Epoch 78/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 476.3104\n",
      "Epoch 79/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 445.4267\n",
      "Epoch 80/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 458.6428\n",
      "Epoch 81/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 506.2565\n",
      "Epoch 82/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 490.2621\n",
      "Epoch 83/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 441.6702\n",
      "Epoch 84/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 527.9205\n",
      "Epoch 85/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 580.3434\n",
      "Epoch 86/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 492.3885\n",
      "Epoch 87/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 538.7453\n",
      "Epoch 88/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 489.8241\n",
      "Epoch 89/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 480.0059\n",
      "Epoch 90/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 507.5142\n",
      "Epoch 91/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 453.0231\n",
      "Epoch 92/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 549.1718\n",
      "Epoch 93/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 499.9514\n",
      "Epoch 94/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 533.1447\n",
      "Epoch 95/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 496.6989\n",
      "Epoch 96/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 470.4152\n",
      "Epoch 97/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 531.1803\n",
      "Epoch 98/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 538.5209\n",
      "Epoch 99/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 531.3533\n",
      "Epoch 100/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 397.4992\n",
      "Epoch 101/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 463.4707\n",
      "Epoch 102/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 598.0605\n",
      "Epoch 103/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 490.0273\n",
      "Epoch 104/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 422.1201\n",
      "Epoch 105/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 550.0555\n",
      "Epoch 106/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 472.3301\n",
      "Epoch 107/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 466.5536\n",
      "Epoch 108/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 444.1395\n",
      "Epoch 109/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 476.5284\n",
      "Epoch 110/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 364.0775\n",
      "Epoch 111/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 481.4121\n",
      "Epoch 112/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 528.0464\n",
      "Epoch 113/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 498.0267\n",
      "Epoch 114/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 493.1089\n",
      "Epoch 115/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 437.5259\n",
      "Epoch 116/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 441.5678\n",
      "Epoch 117/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 542.1608\n",
      "Epoch 118/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 389.8659\n",
      "Epoch 119/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 426.8259\n",
      "Epoch 120/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 445.0027\n",
      "Epoch 121/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 527.4333\n",
      "Epoch 122/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 548.3055\n",
      "Epoch 123/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 384.7938\n",
      "Epoch 124/200\n",
      "47102/47102 [==============================] - 1s 30us/step - loss: 499.8114\n",
      "Epoch 125/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 400.9780\n",
      "Epoch 126/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 394.3861\n",
      "Epoch 127/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 547.5728\n",
      "Epoch 128/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 420.8865\n",
      "Epoch 129/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 452.3515\n",
      "Epoch 130/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 434.0302\n",
      "Epoch 131/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 465.3197\n",
      "Epoch 132/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 417.6235\n",
      "Epoch 133/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 481.5699\n",
      "Epoch 134/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 499.7649\n",
      "Epoch 135/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 418.7079\n",
      "Epoch 136/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 418.7091\n",
      "Epoch 137/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 469.8295\n",
      "Epoch 138/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 458.9090\n",
      "Epoch 139/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 439.6084\n",
      "Epoch 140/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 360.0535\n",
      "Epoch 141/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 408.0026\n",
      "Epoch 142/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 537.5058\n",
      "Epoch 143/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 490.7434\n",
      "Epoch 144/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 500.3260\n",
      "Epoch 145/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 471.8818\n",
      "Epoch 146/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 404.8213\n",
      "Epoch 147/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 462.2452\n",
      "Epoch 148/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 502.2527\n",
      "Epoch 149/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 424.3936\n",
      "Epoch 150/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 461.3788\n",
      "Epoch 151/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 460.6979\n",
      "Epoch 152/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 405.6354\n",
      "Epoch 153/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 365.1587\n",
      "Epoch 154/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 471.9433\n",
      "Epoch 155/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 429.9417\n",
      "Epoch 156/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 397.7349\n",
      "Epoch 157/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 426.0049\n",
      "Epoch 158/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 420.7638\n",
      "Epoch 159/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 496.5041\n",
      "Epoch 160/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 393.9152\n",
      "Epoch 161/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 454.0691\n",
      "Epoch 162/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 453.6877\n",
      "Epoch 163/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 456.6773\n",
      "Epoch 164/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 438.3470\n",
      "Epoch 165/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 524.2150\n",
      "Epoch 166/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 450.4488\n",
      "Epoch 167/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 377.6129\n",
      "Epoch 168/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 464.1062\n",
      "Epoch 169/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 497.4199\n",
      "Epoch 170/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 429.5949\n",
      "Epoch 171/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 412.7750\n",
      "Epoch 172/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 417.2702\n",
      "Epoch 173/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 434.2644\n",
      "Epoch 174/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 454.7045\n",
      "Epoch 175/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 513.0242\n",
      "Epoch 176/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 421.7924\n",
      "Epoch 177/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 495.4176\n",
      "Epoch 178/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 453.4485\n",
      "Epoch 179/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 436.0917\n",
      "Epoch 180/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 416.0967\n",
      "Epoch 181/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 400.6605\n",
      "Epoch 182/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 436.8255\n",
      "Epoch 183/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 419.4038\n",
      "Epoch 184/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 462.3745\n",
      "Epoch 185/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 448.6590\n",
      "Epoch 186/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 391.9387\n",
      "Epoch 187/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 495.5086\n",
      "Epoch 188/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 416.4480\n",
      "Epoch 189/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 375.9469\n",
      "Epoch 190/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 441.4042\n",
      "Epoch 191/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 467.2951\n",
      "Epoch 192/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 472.2179\n",
      "Epoch 193/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 456.6613\n",
      "Epoch 194/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 440.9111\n",
      "Epoch 195/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 444.3876\n",
      "Epoch 196/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 384.1961\n",
      "Epoch 197/200\n",
      "47102/47102 [==============================] - 1s 28us/step - loss: 362.5550\n",
      "Epoch 198/200\n",
      "47102/47102 [==============================] - 1s 27us/step - loss: 363.8959\n",
      "Epoch 199/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 522.6648\n",
      "Epoch 200/200\n",
      "47102/47102 [==============================] - 1s 26us/step - loss: 387.3880\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers, optimizers\n",
    "model = Sequential()\n",
    "model.add(Dense(256, kernel_initializer = 'normal', activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "#model.add(Dense(64, kernel_initializer = 'normal', activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1, \n",
    "                             momentum=0.99, epsilon=0.001, \n",
    "                             center=True, scale=True, \n",
    "                             beta_initializer='zeros', \n",
    "                             gamma_initializer='ones', \n",
    "                             moving_mean_initializer='zeros', \n",
    "                             moving_variance_initializer='ones', \n",
    "                             beta_regularizer=None, gamma_regularizer=None, \n",
    "                             beta_constraint=None, gamma_constraint=None))\n",
    "model.add(Dense(128, activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1, \n",
    "                             momentum=0.99, epsilon=0.001, \n",
    "                             center=True, scale=True, \n",
    "                             beta_initializer='zeros', \n",
    "                             gamma_initializer='ones', \n",
    "                             moving_mean_initializer='zeros', \n",
    "                             moving_variance_initializer='ones', \n",
    "                             beta_regularizer=None, gamma_regularizer=None, \n",
    "                             beta_constraint=None, gamma_constraint=None))\n",
    "model.add(Dense(1))\n",
    "#model.compile(loss = 'rmse', optimizer = 'adam')\n",
    "adm = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f'training data dims: X: {X_train.shape}, y: {y_train.shape}')\n",
    "print(f'test data dims: X: {X_test.shape}, y: {y_test.shape}')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 200, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.8481657608695652\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = predictions.reshape(len(y_test),)\n",
    "difference = predictions - y_test \n",
    "threshold_15 = 0.15*y_test\n",
    "acc_test_15 = sum(threshold_15 - abs(difference) > 0) / len(y_test)\n",
    "print('test accuracy: ', acc_test_15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.854464778565666\n"
     ]
    }
   ],
   "source": [
    "predictions_train = model.predict(X_train)\n",
    "predictions_train = predictions_train.reshape(len(y_train), )\n",
    "threshold_train = 0.15*y_train\n",
    "difference_train = predictions_train - y_train\n",
    "acc_train = sum(threshold_train - abs(difference_train) > 0) / len(y_train)\n",
    "print('train accuracy: ',acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sqrt(history.history['loss']))\n",
    "plt.title('BERT integrated RMSE history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.savefig('bert_rmse.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
