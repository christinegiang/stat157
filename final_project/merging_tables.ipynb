{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "# If pandas is not installed, please uncomment the following line:\n",
    "#!pip install pandas\n",
    "#!pip install sklearn\n",
    "#!pip install pathos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full\n",
    "\n",
    "def read_mimic_csv(path):\n",
    "    start = time.time()\n",
    "    TextFileReader = pd.read_csv(path, chunksize=100000, iterator=True, low_memory=False)\n",
    "    df = pd.concat(TextFileReader, ignore_index=True)\n",
    "    print(path, \":\" , round(time.time() - start, 1), 'seconds')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./payload/full/PATIENTS.csv : 0.1 seconds\n",
      "./payload/full/DIAGNOSES_ICD.csv : 1.0 seconds\n",
      "./payload/full/ADMISSIONS.csv : 0.7 seconds\n"
     ]
    }
   ],
   "source": [
    "path = './payload/full/' # change as needed\n",
    "patients = read_mimic_csv(path + 'PATIENTS.csv')\n",
    "diagnoses = read_mimic_csv(path + 'DIAGNOSES_ICD.csv')\n",
    "admissions = read_mimic_csv(path + 'ADMISSIONS.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICD9 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs = open(\"ccs.txt\", \"r\").read()\n",
    "\n",
    "# Create dictionary. Key is ICD9 code for a diagnosis. Value is general description of diagnosis.\n",
    "ccs = ccs[ccs.find('Tuberculosis'):]\n",
    "icd9={}\n",
    "\n",
    "def update_icd9(cur_value, section):\n",
    "    while section:\n",
    "        if section[:4] == '\\n\\n':\n",
    "            print('new value')\n",
    "            section = section[4:]\n",
    "            cur_value = section[:section.find('\\n')]\n",
    "            section = section[section.find('\\n'):]\n",
    "        elif section[0] == ' ':\n",
    "            section = section[1:]\n",
    "        elif section[:2] == '\\n':\n",
    "            section = section[2:]\n",
    "        else:\n",
    "            if section.find(' ') >= 0: # not end of document\n",
    "                if -1 < section.find('\\n') < section.find(' '): # if end of line\n",
    "                    cur_key = section[:section.find('\\n')]\n",
    "                else: # if not end of line\n",
    "                    cur_key = section[:section.find(' ')]\n",
    "                section = section[section.find(' '):]\n",
    "                icd9[cur_key] = cur_value\n",
    "\n",
    "            else: # end of section\n",
    "                cur_key = section\n",
    "                icd9[cur_key] = cur_value\n",
    "                section = \"\"\n",
    "            \n",
    "for section in ccs.split(sep='\\n\\n'): # for each family of codes\n",
    "    cur_value = section[:section.find('\\n')] # get the name for that family\n",
    "    section = section[section.find('\\n')+1:] # and for all the codes under that family\n",
    "    update_icd9(cur_value, section) # add those codes as keys to a dictionary, where their values\n",
    "                                    # are the name for the family of codes\n",
    "\n",
    "diagnoses.ICD9_CODE = diagnoses.ICD9_CODE.apply(lambda x: icd9.get(x,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create LOS feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# commented out for mortality classification:\n",
    "# admissions = admissions[pd.isnull(admissions['DEATHTIME'])]\n",
    "df = admissions[['SUBJECT_ID',\n",
    "                 'HADM_ID',\n",
    "                 'ADMISSION_TYPE',\n",
    "                 'ADMITTIME']].copy()\n",
    "\n",
    "df['LOS'] = (pd.to_datetime(admissions['DISCHTIME']) - pd.to_datetime(admissions['ADMITTIME'])).astype('timedelta64[h]') \n",
    "df['ADMITTIME'] = pd.to_datetime(admissions['ADMITTIME']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['LOS'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diagnoses = pd.get_dummies(diagnoses[['HADM_ID','ICD9_CODE']], drop_first=False)\n",
    "diagnoses = diagnoses.groupby('HADM_ID').agg('sum')\n",
    "df = pd.merge(df,\n",
    "              diagnoses,\n",
    "              on='HADM_ID',\n",
    "              how='left') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self: There are negative LOS values for when a patient dies prior to arriving to the hospital. I keep these in for mortality classification. But these values kinda lead to meaningless LOS values.\n",
    "\n",
    "#### Extracting age feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mortality classification, I'm keeping DOD_HOSP so I can create a boolean response for death\n",
    "# NB: DOD includes ALL deaths (before & after), while DOD_HOSP only includes deaths occuring inside the hospital. \n",
    "df = pd.merge(df, # drop DOD_HOSP too if not classifying mortality\n",
    "              patients.drop(columns = ['DOD', 'DOD_SSN','ROW_ID','EXPIRE_FLAG']),\n",
    "              on='SUBJECT_ID',\n",
    "              how='left') \n",
    "median_dob_shift = 300 - 91.4 # For old patients (median age of 91.4), dob was shifted to be 300 yrs prior to first visit\n",
    "df['AGE'] = (pd.to_datetime(df['ADMITTIME']).dt.date - pd.to_datetime(df['DOB']).dt.date)\n",
    "df['AGE'] = [age.days/365 if age.days/365<300 else age.days/365-median_dob_shift for age in df['AGE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"DOB is the date of birth of the given patient. Patients who are older than 89 years old at any time in the database have had their date of birth shifted to obscure their age and comply with HIPAA. The shift process was as follows: the patientâ€™s age at their first admission was determined. The date of birth was then set to exactly 300 years before their first admission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting whether-they-died feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['DIED'] = df['DOD_HOSP'].apply(lambda x: not pd.isnull(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trig transform for admit time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADMITHOUR_trig_x'] = pd.to_datetime(df['ADMITTIME']).dt.hour.apply(math.cos)\n",
    "df['ADMITHOUR_trig_y'] = pd.to_datetime(df['ADMITTIME']).dt.hour.apply(math.sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['DOD_HOSP','DOB'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy variables and drop those with less information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before adding dummy variables: (58878, 292)\n",
      "Shape after adding dummy variables: (58878, 294)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before adding dummy variables:',df.shape)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "print('Shape after adding dummy variables:', df.shape)\n",
    "\n",
    "# It turns out ADMITHOUR after trig transform is highly predictive of whether you die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['SUBJECT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_day_chartevents.csv : 0.2 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.464577436447144"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chartevents = read_mimic_csv('first_day_chartevents.csv')\n",
    "first_chartevents = first_chartevents.drop(columns = [\"Unnamed: 0\"])\n",
    "df = pd.merge(df, first_chartevents, on='HADM_ID',\n",
    "              how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_serv_pres_micro.csv : 0.4 seconds\n"
     ]
    }
   ],
   "source": [
    "first_serv_pres_micro = read_mimic_csv('first_serv_pres_micro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_serv_pres_micro = first_serv_pres_micro.drop(columns = ['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hadm = first_serv_pres_micro.index.values\n",
    "first_serv_pres_micro['HADM_ID'] = hadm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, first_serv_pres_micro, on=\"HADM_ID\", how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.11062216758728"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "df.to_csv('pat_adm_diag_chart.csv')\n",
    "\n",
    "time.time() - time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df.to_csv('bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
